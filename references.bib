@techreport{sawant2020human,
  title={Human activity recognition with openpose and Long Short-Term Memory on real time images},
  author={Sawant, Chinmay},
  year={2020},
  institution={EasyChair}
}

@InProceedings{10.1007/978-3-030-20205-7_25,
author="Noori, Farzan Majeed
and Wallace, Benedikte
and Uddin, Md. Zia
and Torresen, Jim",
editor="Felsberg, Michael
and Forss{\'e}n, Per-Erik
and Sintorn, Ida-Maria
and Unger, Jonas",
title="A Robust Human Activity Recognition Approach Using OpenPose, Motion Features, and Deep Recurrent Neural Network",
booktitle="Image Analysis",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="299--310",
abstract="With the emerging advancements in computer vision and pattern recognition, methods for human activity recognition have become increasingly accessible. In this paper, we present a robust approach for human activity recognition which uses the open source library OpenPose to extract anatomical key points from RGB images. We further use these key points to extract robust motion features considering their movements in consecutive frames'. Then, a Recurrent Neural Network (RNN) with Long Short-term Memory cells (LSTM) is used to recognize the activities associated with these features. To make the approach person-independent, different subjects from different camera angles are used. The proposed method shows promising performance, with the best result reaching an overall accuracy of 92.4{\%} on a publicly available activity data set, which outperforms the conventional approaches (i.e. support vector machines, decision trees, and random forests) which achieve maximum accuracy of 78.5{\%}. The proposed activity recognition system can contribute in prominent research fields such as image processing and computer vision with practical applications such as caregiving for older people to help them live more independently.",
isbn="978-3-030-20205-7"
}

@INPROCEEDINGS{Berkeley-MHAD,
  author={ F. Ofli, R. Chaudhry, G. Kurillo, R. Vidal and R. Bajcsy},
  booktitle={IEEE Workshop on Applications on Computer Vision (WACV)}, 
  title={Berkeley MHAD: A Comprehensive Multimodal Human Action Database}, 
  year={2013},
  volume={},
  number={},
  pages={},
}

@INPROCEEDINGS{hierarchical-rnn-har,
  author={ {Yong Du} and W. {Wang} and L. {Wang}},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Hierarchical recurrent neural network for skeleton based action recognition}, 
  year={2015},
  volume={},
  number={},
  pages={1110-1118},
}

@article{DBLP:journals/corr/abs-1812-08008,
  author    = {Zhe Cao and
               Gines Hidalgo and
               Tomas Simon and
               Shih{-}En Wei and
               Yaser Sheikh},
  title     = {OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity
               Fields},
  journal   = {CoRR},
  volume    = {abs/1812.08008},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.08008},
  archivePrefix = {arXiv},
  eprint    = {1812.08008},
  timestamp = {Wed, 02 Jan 2019 14:40:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-08008.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/CaoSWS16,
  author    = {Zhe Cao and
               Tomas Simon and
               Shih{-}En Wei and
               Yaser Sheikh},
  title     = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  journal   = {CoRR},
  volume    = {abs/1611.08050},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.08050},
  archivePrefix = {arXiv},
  eprint    = {1611.08050},
  timestamp = {Mon, 13 Aug 2018 16:47:26 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/CaoSWS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{10.3389/frobt.2015.00028,
  
AUTHOR={Vrigkas, Michalis and Nikou, Christophoros and Kakadiaris, Ioannis A.},   
   
TITLE={A Review of Human Activity Recognition Methods},      
  
JOURNAL={Frontiers in Robotics and AI},      
  
VOLUME={2},      

PAGES={28},     
  
YEAR={2015},      
    
URL={https://www.frontiersin.org/article/10.3389/frobt.2015.00028},       
  
DOI={10.3389/frobt.2015.00028},      
  
ISSN={2296-9144},   
   
ABSTRACT={Recognizing human activities from video sequences or still images is a challenging task due to problems, such as background clutter, partial occlusion, changes in scale, viewpoint, lighting, and appearance. Many applications, including video surveillance systems, human-computer interaction, and robotics for human behavior characterization, require a multiple activity recognition system. In this work, we provide a detailed review of recent and state-of-the-art research advances in the field of human activity classification. We propose a categorization of human activity methodologies and discuss their advantages and limitations. In particular, we divide human activity classification methods into two large categories according to whether they use data from different modalities or not. Then, each of these categories is further analyzed into sub-categories, which reflect how they model human activities and what type of activities they are interested in. Moreover, we provide a comprehensive analysis of the existing, publicly available human activity classification datasets and examine the requirements for an ideal human activity recognition dataset. Finally, we report the characteristics of future research directions and present some open issues on human activity recognition.}
}


@article{kinematic-back-handspring-analysis,
author = {Penitente, Gabriella and Merni, Franco and Sands, William},
year = {2011},
month = {01},
pages = {1-11},
title = {Kinematic analysis of the centre of mass in the back handspring: A case study},
volume = {4},
journal = {Gym Coach}
}

@inproceedings{Burgess2001KINEMATICAO,
  title={KINEMATIC ANALYSIS OF THE BACK SALTO TAKE-OFF IN A TUMBLING SERIES: ADVANCED VS. BEGINNER TECHNIQUES},
  author={Robyn Burgess and Guillermo J. Noffal},
  year={2001}
}

@article{poseestimation2015convnets,
author = {Pfister, Tomas and Charles, James and Zisserman, Andrew},
year = {2015},
month = {06},
pages = {},
title = {Flowing ConvNets for Human Pose Estimation in Videos},
doi = {10.1109/ICCV.2015.222}
}

@misc{posenet,
  title = {PoseNet},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tensorflow/tfjs-models/tree/master/posenet}},
}

@misc{openpose-python-pose-extraction-module,
  title = {OpenPose Python Pose Extraction Module},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/AllarVi/openpose-extract}},
}

@misc{openpose-requirements-and-dependencies,
  title = {OpenPose Requirements and Dependencies},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/installation.md\#requirements-and-dependencies}},
}

@misc{wrnchai,
  title = {wrnchAI,
  year = {2020},
  howpublished = {\url{https://wrnch.ai/technology/}},
}