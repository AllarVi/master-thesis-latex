@ARTICLE{7567551,
  author={I. H. {López-Nava} and A. {Muñoz-Meléndez}},
  journal={IEEE Sensors Journal},
  title={Wearable Inertial Sensors for Human Motion Analysis: A Review},
  year={2016},
  volume={16},
  number={22},
  pages={7821-7834},
}

@InProceedings{Elhayek_2015_CVPR,
author = {Elhayek, Ahmed and de Aguiar, Edilson and Jain, Arjun and Tompson, Jonathan and Pishchulin, Leonid and Andriluka, Micha and Bregler, Chris and Schiele, Bernt and Theobalt, Christian},
title = {Efficient ConvNet-Based Marker-Less Motion Capture in General Scenes With a Low Number of Cameras},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@article{NUNEZ201880,
title = "Convolutional Neural Networks and Long Short-Term Memory for skeleton-based human activity and hand gesture recognition",
journal = "Pattern Recognition",
volume = "76",
pages = "80 - 94",
year = "2018",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2017.10.033",
url = "http://www.sciencedirect.com/science/article/pii/S0031320317304405",
author = "Juan C. Núñez and Raúl Cabido and Juan J. Pantrigo and Antonio S. Montemayor and José F. Vélez",
keywords = "Deep learning, Convolutional Neural Network, Recurrent neural network, Long Short-Term Memory, Human activity recognition, Hand gesture recognition, Real-time",
abstract = "In this work, we address human activity and hand gesture recognition problems using 3D data sequences obtained from full-body and hand skeletons, respectively. To this aim, we propose a deep learning-based approach for temporal 3D pose recognition problems based on a combination of a Convolutional Neural Network (CNN) and a Long Short-Term Memory (LSTM) recurrent network. We also present a two-stage training strategy which firstly focuses on CNN training and, secondly, adjusts the full method (CNN+LSTM). Experimental testing demonstrated that our training method obtains better results than a single-stage training strategy. Additionally, we propose a data augmentation method that has also been validated experimentally. Finally, we perform an extensive experimental study on publicly available data benchmarks. The results obtained show how the proposed approach reaches state-of-the-art performance when compared to the methods identified in the literature. The best results were obtained for small datasets, where the proposed data augmentation strategy has greater impact."
}

@article{DBLP:journals/corr/Lipton15,
  author    = {Zachary Chase Lipton},
  title     = {A Critical Review of Recurrent Neural Networks for Sequence Learning},
  journal   = {CoRR},
  volume    = {abs/1506.00019},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.00019},
  archivePrefix = {arXiv},
  eprint    = {1506.00019},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Lipton15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{deep-learning-cookbook,
    title={Deep Learning Cookbook},
    author={Douwe Osinga},
    publisher={O\'Reilly Media, Inc.},
    note={\url{https://www.oreilly.com/library/view/deep-learning-cookbook/9781491995839}},
    year={2018}
}

@techreport{sawant2020human,
  title={Human activity recognition with openpose and Long Short-Term Memory on real time images},
  author={Sawant, Chinmay},
  year={2020},
  institution={EasyChair}
}

@InProceedings{10.1007/978-3-030-20205-7_25,
author="Noori, Farzan Majeed
and Wallace, Benedikte
and Uddin, Md. Zia
and Torresen, Jim",
editor="Felsberg, Michael
and Forss{\'e}n, Per-Erik
and Sintorn, Ida-Maria
and Unger, Jonas",
title="A Robust Human Activity Recognition Approach Using OpenPose, Motion Features, and Deep Recurrent Neural Network",
booktitle="Image Analysis",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="299--310",
abstract="With the emerging advancements in computer vision and pattern recognition, methods for human activity recognition have become increasingly accessible. In this paper, we present a robust approach for human activity recognition which uses the open source library OpenPose to extract anatomical key points from RGB images. We further use these key points to extract robust motion features considering their movements in consecutive frames'. Then, a Recurrent Neural Network (RNN) with Long Short-term Memory cells (LSTM) is used to recognize the activities associated with these features. To make the approach person-independent, different subjects from different camera angles are used. The proposed method shows promising performance, with the best result reaching an overall accuracy of 92.4{\%} on a publicly available activity data set, which outperforms the conventional approaches (i.e. support vector machines, decision trees, and random forests) which achieve maximum accuracy of 78.5{\%}. The proposed activity recognition system can contribute in prominent research fields such as image processing and computer vision with practical applications such as caregiving for older people to help them live more independently.",
isbn="978-3-030-20205-7"
}

@INPROCEEDINGS{Berkeley-MHAD,
  author={ F. Ofli, R. Chaudhry, G. Kurillo, R. Vidal and R. Bajcsy},
  booktitle={IEEE Workshop on Applications on Computer Vision (WACV)}, 
  title={Berkeley MHAD: A Comprehensive Multimodal Human Action Database}, 
  year={2013},
  volume={},
  number={},
  pages={},
}

@INPROCEEDINGS{hierarchical-rnn-har,
  author={ {Yong Du} and W. {Wang} and L. {Wang}},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Hierarchical recurrent neural network for skeleton based action recognition}, 
  year={2015},
  volume={},
  number={},
  pages={1110-1118},
}

@article{DBLP:journals/corr/abs-1812-08008,
  author    = {Zhe Cao and
               Gines Hidalgo and
               Tomas Simon and
               Shih{-}En Wei and
               Yaser Sheikh},
  title     = {OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity
               Fields},
  journal   = {CoRR},
  volume    = {abs/1812.08008},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.08008},
  archivePrefix = {arXiv},
  eprint    = {1812.08008},
  timestamp = {Wed, 02 Jan 2019 14:40:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-08008.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/CaoSWS16,
  author    = {Zhe Cao and
               Tomas Simon and
               Shih{-}En Wei and
               Yaser Sheikh},
  title     = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  journal   = {CoRR},
  volume    = {abs/1611.08050},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.08050},
  archivePrefix = {arXiv},
  eprint    = {1611.08050},
  timestamp = {Mon, 13 Aug 2018 16:47:26 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/CaoSWS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{10.3389/frobt.2015.00028,
  
AUTHOR={Vrigkas, Michalis and Nikou, Christophoros and Kakadiaris, Ioannis A.},   
   
TITLE={A Review of Human Activity Recognition Methods},      
  
JOURNAL={Frontiers in Robotics and AI},      
  
VOLUME={2},      

PAGES={28},     
  
YEAR={2015},      
    
URL={https://www.frontiersin.org/article/10.3389/frobt.2015.00028},       
  
DOI={10.3389/frobt.2015.00028},      
  
ISSN={2296-9144},   
   
ABSTRACT={Recognizing human activities from video sequences or still images is a challenging task due to problems, such as background clutter, partial occlusion, changes in scale, viewpoint, lighting, and appearance. Many applications, including video surveillance systems, human-computer interaction, and robotics for human behavior characterization, require a multiple activity recognition system. In this work, we provide a detailed review of recent and state-of-the-art research advances in the field of human activity classification. We propose a categorization of human activity methodologies and discuss their advantages and limitations. In particular, we divide human activity classification methods into two large categories according to whether they use data from different modalities or not. Then, each of these categories is further analyzed into sub-categories, which reflect how they model human activities and what type of activities they are interested in. Moreover, we provide a comprehensive analysis of the existing, publicly available human activity classification datasets and examine the requirements for an ideal human activity recognition dataset. Finally, we report the characteristics of future research directions and present some open issues on human activity recognition.}
}


@article{kinematic-back-handspring-analysis,
author = {Penitente, Gabriella and Merni, Franco and Sands, William},
year = {2011},
month = {01},
pages = {1-11},
title = {Kinematic analysis of the centre of mass in the back handspring: A case study},
volume = {4},
journal = {Gym Coach}
}

@article{doi:10.1080/14763140608522878,
author = { Spiros   Prassas  and  Young‐Hoo   Kwon  and  William A.   Sands },
title = {Biomechanical research in artistic gymnastics: a review},
journal = {Sports Biomechanics},
volume = {5},
number = {2},
pages = {261-291},
year  = {2006},
publisher = {Routledge},
doi = {10.1080/14763140608522878},
    note ={PMID: 16939157},
URL = { 
        https://doi.org/10.1080/14763140608522878
    
},
eprint = { 
        https://doi.org/10.1080/14763140608522878   
}
}

@inproceedings{Burgess2001KINEMATICAO,
  title={KINEMATIC ANALYSIS OF THE BACK SALTO TAKE-OFF IN A TUMBLING SERIES: ADVANCED VS. BEGINNER TECHNIQUES},
  author={Robyn Burgess and Guillermo J. Noffal},
  year={2001}
}

@article{poseestimation2015convnets,
author = {Pfister, Tomas and Charles, James and Zisserman, Andrew},
year = {2015},
month = {06},
pages = {},
title = {Flowing ConvNets for Human Pose Estimation in Videos},
doi = {10.1109/ICCV.2015.222}
}

@misc{posenet,
  title = {PoseNet},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tensorflow/tfjs-models/tree/master/posenet}},
}

@misc{nvidiat4,
  title = {NVIDIA T4 Tensor Core GPU for AI Inference | NVIDIA Data Center},
  year = {2020},
  publisher = {NVIDIA},
  journal = {NVIDIA},
  howpublished = {\url{https://www.nvidia.com/en-us/data-center/tesla-t4}},
}

@misc{openpose-python-pose-extraction-module,
  title = {OpenPose Python Pose Extraction Module},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/AllarVi/openpose-extract}},
}

@misc{openpose-requirements-and-dependencies,
  title = {OpenPose Requirements and Dependencies},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/installation.md\#requirements-and-dependencies}},
}

@misc{wrnchai,
  title = {wrnchAI,
  year = {2020},
  howpublished = {\url{https://wrnch.ai/technology/}},
}