\begin{comment}

\end{comment}

\section{Classifiers comparison}

All classifiers presented in this thesis have outstanding results with distinguishing the two gymnastics elements - backflip and back handspring. The results show impressive potential distinguishing short duration complex body moments. It is worth to mention that the time-series input data also contains full rotation of human body, separating this work from other example works using recurrent neural networks to recognize simple human actions \cite{sawant2020human}. Backflips and back handsprings are similar actions in terms of human body movement, differentiating mostly in the way that during the backflip's rotation athlete's arms are not extended and also noticeable vertical movement occurs during the back handspring push off phase (section \ref{back-handspring-description-section}). The table \ref{classifier-wall-time} depicts all classifiers with corresponding average test accuracy for 5 unrelated model training runs. The table also contains total wall time for all classifiers with noticeable difference in the duration, clearly demonstrating how more complex neural network architectures require more computational power. 

With the dataset used for experimentation, the classifiers tend to be sensitive to overfitting, requiring heuristic hyperparameter tuning. The author's training process involved training the classifiers to overfit at first runs and using hyperparameter tuning with callbacks to finish training before reaching 100\% accuracy. With a training set of 1514 samples, all recurrent classifiers finish at sub-hundred percent accuracy, enabling the comparison of classifier accuracy ratios.

With equal sample sizes and training epochs, the hierarchical RNN finishes with the highest average accuracy of 99.909\%, however requiring four times as much training time as the \textit{SimpleRNN} classifier, with no substantial loss of average accuracy. The hierarchical RNN provides more interpret-ability with body part specific neuron activations. In summary, experimental results show positive potential using recurrent network architectures for differentiating gymnastics movements, such as backflips and back handsprings. 

\begin{table}[htb]
\begin{tabular}{llll}
Classifier            & SimpleRnn & LSTM      & Hierarchical RNN  \\
Average test accuracy & 94.467\%  & 88.405\%  &  99.909\%         \\
Wall time             & 13min 4s  & 30min 34s & 1h 1min 38s       \\
 &  &  &  
\end{tabular}
\caption{More complex classifier architecture strongly impacts wall time when training recurrent neural networks to distinguish gymnastics elements}
\label{classifier-wall-time}
\end{table}

\section{Future work}

Even though this thesis successfully demonstrates an end-to-end solution for gymnastics action classification, it is not an out-of-the-box readily usable solution and has a lot of potential for improvements. Following, is a brief discussion about some ideas for future work:

\begin{easylist}[enumerate]

& \textit{Real-time recognition with action classification} --- The potential of current work includes packaging the code and deploying it as a backend service. For this, some restructuring of the code is necessary. Also, two main services should be developed for better contextual boundaries. The first service should deal with the pose estimation and pre-processing of the data. For pose estimation, the advice would be to deploy OpenPose on a server with at least one graphics processing unit and the data-preprocessing strategies have been thoroughly described in section \ref{data-pre-processing-strategies}. The Python based technology stack used for data pre-processing in this thesis was used mainly for demonstration and validation purposes. The second proposed backend service would be responsible for the classification task of gymnastics action recognition. After initial model training, the model should be deployed as backend service with prediction API usable by a controller tier application. It should also be feasible to implement the continuous learning of the model. For complete real-time solution, a controller tier application should be developed, aggregating the two main backend services described before. The controller tier application should be deployed onto a device with video recording capabilities, i.e. a smart phone.

& \textit{Multi-person action recognition} --- For increasing the robustness and field usability of the solution developed in current thesis, a concurrent multi-person recognition support should be implemented. Many gymnastics athletes tend to train in groups and capturing multiple persons in the same frame is unavoidable without interfering too much with the formation of training groups in gymnastics facilities. 

OpenPose already offers the indexing of each frame's pose estimation. By grouping and filtering, it is possible to implement a solution for filtering out the bystanders in the subject's frame and targeting only athletes of interest for action recognition.

& \textit{3D poses with burst photography} --- At the time of writing this paper, researchers Dan Oved, Amelia Pisapia and Anna Gudnason from the \textit{New York Times} published an article with interesting advancements in the pose estimation field, while also focusing on the sports of gymnastics. Using a similar pose estimation tool \textit{Wrnch} \cite{wrnchai}, an alternative to \textit{OpenPose}, they have improved real-time pose estimation in gymnastics by constructing a 3D pose by triangulating using 2D poses and using burst photography instead of video, yielding sharper and higher-resolution images than video \cite{nyt-pose-estimation}. Similar improvements could be made to the solution developed in this thesis. Additionally, with improved poses, researchers were able to extract gymnastics related metrics, such as jump height, body acceleration and rotation speed. These metrics could prove as useful features for non-invasive human action recognition. Further research with mentioned metrics should be conducted when improving the recognition of gymnastics elements. 
    
\end{easylist}






















